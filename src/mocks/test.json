그냥 10문제
[
  [
    {
      "question": "1. 분류와 군집화의 차이는 무엇인가요?",
      "answer": "분류는 그룹 정보가 이미 알려진 상태에서 데이터를 그룹화하는 방법이고, 군집화는 그룹 정보가 없는 상태에서 유사한 데이터를 묶는 방법입니다."
    },
    {
      "question": "2. k-NN 알고리즘은 무엇에 사용되나요?",
      "answer": "k-NN(최근접 이웃) 알고리즘은 분류 문제에 사용되며, 훈련 집합 내 k개의 가장 가까운 이웃에 대한 유사성을 기반으로 데이터를 분류합니다."
    },
    {
      "question": "3. k-NN 알고리즘의 단점은 무엇인가요?",
      "answer": "k-NN 알고리즘은 많은 메모리와 계산을 필요로 하며, 특히 데이터에 많은 특징과 클래스가 있는 경우에 더욱 그렇습니다."
    },
    {
      "question": "4. k-NN 알고리즘을 사용하기 전에 어떤 데이터 전처리가 요구되나요?",
      "answer": "각 객체에 대해 동일한 속성 수를 가진 배열로 데이터가 구성되어야 하며, 일관성을 보장하기 위해 데이터가 표준화되어야 합니다."
    },
    {
      "question": "5. k-NN 알고리즘을 사용하여 새로운 데이터의 클래스는 어떻게 결정되나요?",
      "answer": "새 데이터의 클래스는 k개의 가장 가까운 이웃들의 과반수 클래스를 기반으로 결정됩니다."
    },
    {
      "question": "6. 지도 학습과 비지도 학습의 차이점은 무엇인가요?",
      "answer": "지도 학습은 이미 알려진 출력값을 가진 데이터를 모델링하는 작업이고 비지도 학습은 출력값이 알려지지 않은 데이터에서 구조나 패턴을 찾는 작업입니다."
    },
    {
      "question": "7. 군집화의 목적은 무엇인가요?",
      "answer": "군집화의 목적은 사전 정보나 레이블 없이 유사한 데이터를 묶는 것입니다."
    },
    {
      "question": "8. 데이터 기반 학습의 평가 메트릭은 무엇인가요?",
      "answer": "데이터 기반 학습의 평가 메트릭은 모델의 예측이 데이터의 실제 레이블과 얼마나 일치하는지를 나타내는 정확도입니다."
    },
    {
      "question": "9. k-NN 알고리즘의 성능에 영향을 미치는 요인은 무엇인가요?",
      "answer": "k의 값, 거리 측정 방법과 훈련 집합의 품질 등이 k-NN 알고리즘의 성능에 영향을 미칠 수 있습니다."
    },
    {
      "question": "10. k-NN 알고리즘의 장점은 무엇인가요?",
      "answer": "k-NN 알고리즘은 이해하기 쉽고, 준비나 훈련 시간이 필요하지 않으며, 비선형 데이터를 다룰 수 있다는 것입니다."
    }
  ],
  [
    {
      "question": "1. k-NN은 무엇이며 어떻게 작동하나요?",
      "answer": "k-NN은 K-Nearest Neighbors의 약자입니다. 학습 데이터 집합에서 k개의 가장 가까운 데이터 포인트를 찾아 가장 일반적인 클래스를 선택하여 알 수 없는 데이터 포인트를 분류합니다."
    },
    {
      "question": "2. Samoyed dog 예제에서 s_data와 s_label 배열을 만드는 방법은 무엇인가요?",
      "answer": "numpy.random.randn 함수를 사용하여 s_data 배열을 생성하고 이를 s_label 배열과 같은 크기로 재구성합니다. s_label 배열은 1로 채워진 배열이어야 하며, s_data와 동일한 길이여야 합니다."
    },
    {
      "question": "3. Samoyed dog 예제에서 dog_classes 딕셔너리의 목적은 무엇인가요?",
      "answer": "dog_classes 딕셔너리는 모델에서 클래스에 레이블을 할당하는 데 사용됩니다. 이를 통해 모델의 출력을 더 잘 이해할 수 있도록 도와주며, 어떤 클래스가 어떤 레이블에 해당하는지 알 수 있도록 합니다."
    },
    {
      "question": "4. Iris 꽃 데이터 세트는 무엇이며 어떻게 유용한가요?",
      "answer": "Iris 꽃 데이터 세트는 다른 종류의 Iris 꽃의 여러 속성 측정값으로 구성된 데이터 세트입니다. 이는 분류 모델에 유용하며, 종종 기계 학습 연구에서 벤치마크로 사용됩니다."
    },
    {
      "question": "5. Iris 데이터 세트 예제에서 numpy 배열을 pandas 데이터프레임으로 어떻게 만들 수 있나요?",
      "answer": "pandas.DataFrame() 함수를 사용하여 데이터를 data 인수로, 열 이름의 리스트를 columns 인수로 전달합니다."
    },
    {
      "question": "6. Iris 데이터 세트 예제에서 훈련 데이터와 검증 데이터의 차이점은 무엇인가요?",
      "answer": "훈련 데이터는 모델을 가르치는 데 사용되며, 데이터 세트에서 무작위로 선택됩니다. 검증 데이터는 훈련에 사용되지 않으며 모델의 정확도를 테스트하기 위한 데이터 세트의 하위 집합입니다."
    },
    {
      "question": "7. Iris 데이터 세트 예제에서 k-NN 모델의 정확도를 어떻게 측정할 수 있나요?",
      "answer": "sklearn.metrics.accuracy_score() 함수를 사용하여 모델의 예측 결과(y_pred)와 테스트 세트의 실제 출력(y_test)를 비교합니다."
    },
    {
      "question": "8. 혼동 행렬은 무엇인가요?",
      "answer": "혼동 행렬(confusion matrix)은 이진 분류 모델의 진짜 양성, 거짓 양성, 진짜 음성, 거짓 음성 카운트를 보여주는 테이블입니다."
    },
    {
      "question": "9. 표집 편향이란 무엇인가요?",
      "answer": "표본 편향(sampling bias)은 모델을 훈련하기 위해 사용된 샘플이 보다 일반적인 인구를 대표하지 못하므로 부정확한 예측을 유발합니다."
    },
    {
      "question": "10. 표집 편향은 머신러닝 모델의 성능에"
    }
  ],
  [
    {
      "question": "1. 정밀도(precision)와 재현율(recall)은 무엇인가요?",
      "answer": "정밀도는 전체 예측된 양성 중 올바르게 예측한 양성의 비율, 재현율은 전체 실제 양성 중 올바르게 예측한 양성의 비율입니다."
    },
    {
      "question": "2. 혼동 행렬이란 무엇인가요?",
      "answer": "분류 모델의 예측값을 실제값과 비교하여 성능을 평가하는 행렬입니다."
    },
    {
      "question": "3. 정확도를 구하는 공식은 무엇인가요?",
      "answer": "정확도는 TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative) 값에 대한 비율로 (TP+TN)/(TP+FP+FN+TN)으로 구합니다."
    },
    {
      "question": "4. 진짜 양성 비율(TPR)이란 무엇인가요?",
      "answer": "TPR은 재현율이라고도 하며, 올바르게 예측한 양성 중 실제 양성의 비율입니다."
    },
    {
      "question": "5. 정밀도란 무엇인가요?",
      "answer": "정밀도는 전체 예측한 양성 중 올바르게 예측한 양성의 비율입니다."
    },
    {
      "question": "6. F1 점수란 무엇인가요?",
      "answer": "F1 점수는 정밀도와 재현율의 조화 평균으로 모델의 정확도를 측정하는 지표입니다."
    },
    {
      "question": "7. 앙상블 학습이란 무엇인가요?",
      "answer": "앙상블 학습은 여러 모델을 결합하여 정확도를 향상시키는 기법입니다."
    },
    {
      "question": "8. 앙상블 학습에서 다양성이란 무엇인가요?",
      "answer": "앙상블 학습에서 다양성은 각 모델 사이의 차이를 의미합니다. 이는 모든 모델이 같은 오류를 만들 가능성을 줄입니다."
    },
    {
      "question": "9. 앙상블 학습에서 다양한 모델을 사용하는 이유는 무엇인가요?",
      "answer": "앙상블 학습에서 다양한 모델을 사용하면 모델의 다양성이 증가되어 정확도가 향상됩니다."
    },
    {
      "question": "10. 앙상블 학습의 주요 장점은 무엇인가요?",
      "answer": "앙상블 학습의 주요 장점은 개별 모델의 성능 한계를 극복하여 정확도를 높일 수 있다는 것입니다."
    }
  ],
  [
    {
      "question": "1. 지도 학습과 비지도 학습의 차이점은 무엇인가요?",
      "answer": "지도 학습은 입력 데이터와 예상 결과 데이터가 있지만, 비지도 학습은 결과 데이터가 없습니다."
    },
    {
      "question": "2. 기계 학습에서 배깅 기법이란 무엇인가요?",
      "answer": "배깅 기법은 다른 분류기의 학습에 사용할 수 있는 데이터를 선택하는 기술입니다."
    },
    {
      "question": "3. 기계 학습에서 부스팅 기법이란 무엇인가요?",
      "answer": "부스팅 기법은 분류기의 성능을 개선하는 기술입니다."
    },
    {
      "question": "4. AdaBoost 알고리즘이란 무엇인가요?",
      "answer": "AdaBoost 알고리즘은 가장 많이 사용되는 분류기 부스팅 알고리즘입니다."
    },
    {
      "question": "5. 비지도 학습의 군집화란 무엇인가요?",
      "answer": "군집화는 그룹 지정에 대한 지식이 없는 유사한 데이터를 묶는 것입니다."
    },
    {
      "question": "6. 기계 학습에서 k-평균 알고리즘이 어떤 용도로 사용되나요?",
      "answer": "k-평균 알고리즘은 데이터를 그룹으로 군집화하는 데 사용될 수 있습니다."
    },
    {
      "question": "7. k-평균 알고리즘의 단점은 무엇인가요?",
      "answer": "k-평균 알고리즘의 단점은 클러스터의 개수를 미리 지정해야 한다는 것입니다."
    },
    {
      "question": "8. 사전 지식으로 k-평균 알고리즘을 어떻게 개선할 수 있나요?",
      "answer": "사전 지식을 사용하여 k-평균 알고리즘을 모범 샘플로 초기화하여 성능을 개선할 수 있습니다."
    },
    {
      "question": "9. k-NN과 k-평균 알고리즘의 차이점은 무엇인가요?",
      "answer": "k-NN은 지도 학습 알고리즘이며 k-평균은 비지도 학습 알고리즘입니다."
    },
    {
      "question": "10. 비지도 학습에서 군집화의 주요 목적은 무엇인가요?",
      "answer": "비지도 학습에서 군집화의 주요 목적은 데이터를 이해하고 의미 있는 그룹을 생성하는 것입니다."
    }
  ]
]
